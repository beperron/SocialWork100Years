---
title: '100 Years of Social Work Research: A Data Science Perspective'
output: html_document
---

# Overview of data

The original data were from a search of PsychInfo using Ebsco Host platform (December 23, 2014). The following search operators and limiters were used:   

+ SO "social work" OR SO "social welfare" OR SO "social casework" OR SO "social services"    

+ Limiters - Document Type: Journal Article 

+ Search modes - Boolean/Phrase	Interface - EBSCOhost Research Databases 

+ Search Screen - Advanced Search 

+ Database - PsycINFO

The search results were exported in a _generic bibliographic format_, which is an unstructured text (*.txt) file.The text file was processed using the `BibWrangleR` function created by the first author.  


# Initialize OS-X workspace and functions for data wrangling

This section processes raw data.  This section of code is executed only one time to transform raw text data into an analyzable format.  When new data are obtained for this study (i.e., updated search results), this section should be re-run by changing `echo=FALSE` to `echo=TRUE` in the knitr markdown argument.   

```{r initialization_dataprocessing, warning=FALSE, message=FALSE, eval=FALSE}
# Clear workspace
rm(list=ls())

# Read BWR functions for Mac OS
source("/Users/beperron/Git/BibWrangleR/functions/piWrangleR.R")
source("/Users/beperron/Git/BibWrangleR/functions/packages.R")
# Set the path where original raw data are stored
setwd("/Users/beperron/Git/SocialWorkResearch")

# Set the working directory to store files created by BWR functions
my.path <- "/Users/beperron/Git/SocialWorkResearch"

# Wrangle the data with the BWR function suite
#piBWR.f(csv=FALSE, path=my.path)
#save(pi.df, file = "piArticles.R")
```

# Initialize Windows workspace and functions for data wrangling













# Initialize workspace and functions for analaysis 

All the analyses performed involve the data that have been processed with the `BibWrangleR` functions.  This section reads the processed data, loads the required packages, and does a quick quality check to ensure that the same number of articles (i.e., records) contained in the original search match the number of articles in the transformed data.  

```{r initialization_analysis, message=FALSE, warning=FALSE, comment=NA}
rm(list=ls())
setwd("/Users/beperron/Git/SocialWorkResearch")
source("/Users/beperron/Git/BibWrangleR/functions/ggsurv.R")
load("piArticles.R")
library(dplyr)
library(ggplot2)
library(gridExtra)
library(survival)
library(grid)
library(png)


# Inspect dimensions of the data file (Rows X Columns)
dim(pi.df)

# Inspect variable names of the data file
names(pi.df)

# How many unique article titles?  Ebsco Results of most current search is $n=24,314$. Do not proceed with analysis if the output does not match this result.  
length(which(pi.df$attributes == "TI"))
```


## What is the overall number and names of journal titles? 

```{r unique_titles}
unique.titles <- filter(pi.df, attributes == "SO")

# Number of unique titles
length(unique(unique.titles$record))

# Unique titles
unique(unique.titles$record)
```

## Number of unique journal titles by year

```{r unique_titles_year, message=FALSE, comment=NA, warning=FALSE, fig.height=2, fig.height=4}
journals.year <- tbl_df(pi.df)

year <- journals.year %>%
        filter(attributes == "YR") %>%
        select(id = articleID, year = record)

journals <- journals.year %>%
        filter(attributes == "SO") %>%
        select(id = articleID, journal.title = record)

n.journals.year <- journals %>% 
        left_join(year) %>%
        group_by(year) %>%
        distinct(journal.title) %>%
        summarise(n = n())

journal.count <- ggplot(n.journals.year, aes(as.numeric(year), y=n, group=1)) + 
    geom_line(colour="black") +
    #geom_point(colour="red") + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
    xlab("year") + 
    ylab("frequency") + 
    ggtitle("Number of Journals by Year") + 
    scale_x_continuous(breaks=seq(1914, 2014, 5))
        
journal.count
```


## What journals published the most number of articles

```{r journal_output}

n.so.yr <- filter(pi.df, attributes == "SO" | attributes == "YR")

n.so <- filter(pi.df, attributes == "SO") %>% mutate(title = record) %>% 
        select(-attributes, -record)

n.yr <- filter(pi.df, attributes == "YR") %>% mutate(year = record ) %>% 
        select(-attributes, -record)

n.so.yr <- left_join(n.so, n.yr) %>%
    group_by(title) %>%
    summarise(first = min(year), last = max(year), n.to.date = n()) %>%
    arrange(desc(n.to.date))

# 10 highest number of publications
head(n.so.yr, 10)
```

## What is the lifespan of journals?  

```{r journal_lifespan}
#10 longest running journals 
longest.running <- n.so.yr %>%
       mutate(last = as.numeric(last), first = as.numeric(first), 
              year.diff = last - first) %>%
       arrange(desc(year.diff)) %>%
       select(title, first, last, year.diff) %>%
       mutate(stop = year.diff, event = ifelse(as.numeric(last) != 2014, 1, 0)) %>%
       select(title, stop, event, as.numeric(first))

survival.journals <- survfit(Surv(longest.running$stop+1, longest.running$event) ~ 1)
median.survival <- data.frame(time = c(12,12), quant = c(.5,0))

head(longest.running)

ggsurv(survival.journals) + 
    geom_line(data = median.survival, aes(time, quant), linetype="longdash") +
    annotate("segment", x = 18, xend = 12, y = .12, yend = .15, size = .25, arrow =arrow()) +
    geom_text(x = 29, y =.12, label = "median survival", size = 4) + 
    geom_text(x = 75, y =.75, label = "+ = Last year in print", size = 4) 







```

## What is the number of articles published per year

```{r articles_per_year}
n.articles.year <- filter(pi.df, attributes == "YR") 
year.split <- split(n.articles.year, n.articles.year$record)
year.count <- unlist(lapply(year.split, nrow))
year.count <- year.count[order(names(year.count))]
years <- names(year.count)

df <- data.frame(years, year.count)
rownames(df) <- NULL

plot.article.count <- ggplot(df, aes(as.factor(years), 
                    y = year.count, group=1)) + 
    geom_line(colour="black") +
    #geom_point(colour="red") + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
    xlab("year") + 
    ylab("count") + 
    ggtitle("Number of Studies by Year") +
    scale_x_discrete(breaks=c(seq(1914, 2014, 10))) +
    scale_y_continuous(breaks = c(seq(0, 2000, 250))) 

df$years <- as.numeric(as.character(df$years))

plot.article.cumulative <- ggplot(df, aes(x = years, y = cumsum(year.count))) + 
    geom_line() + 
    theme(axis.text.x = element_text(angle=45, hjust=1)) +
    scale_x_continuous(breaks=pretty(df$years)) +
    xlab("year") +  
    ylab("count") +
    scale_x_continuous(breaks = c(seq(1914,2014,10))) +
    scale_y_continuous(breaks = c(seq(0, 25000, 2500))) + 
    ggtitle("Cumulative Frequency")

grid.arrange(plot.article.count, plot.article.cumulative, ncol=2)

# Print most recent ten years
head(df, 10)
```


# What are the topic areas (by Subject Terms)?

```{r subject_terms_overall, comment=NA, warning=FALSE, message=FALSE}

su.df <- filter(pi.df, attributes == "SU")

subject.terms <- stringr::str_split(su.df$record, pattern = ";")
subject.terms <- unlist(lapply(subject.terms, function(x) gsub(" ", "", x)))

subject.terms.total <- length(unlist(lapply(subject.terms, 
                        function(x) gsub(" ", "", x))))

subject.terms.unique <- length(unique(subject.terms))

most.frequent <- as.data.frame(table(subject.terms))

most.frequent <- arrange(most.frequent, desc(Freq))

# Print 25 most commmon terms
head(most.frequent, 25)

```

## What are the topic areas over time (by Subject terms)?

```{r subject_terms_overtime, warning=FALSE, message=FALSE}
decade <- filter(pi.df, attributes == "YR") %>%
    mutate(year = as.numeric(record)) %>% select(-record, -attributes)

decade$year <- cut(decade$year, breaks = 10, labels = c(1:10))

keywords <- pi.df %>%
        filter(attributes == "SU") %>%
        select(articleID = articleID, keywords = record)

keywords.decade <- keywords %>% 
         left_join(decade)

library(plyr)
keywords.data.split <- dlply(keywords.decade, .(year))
detach(package:plyr)

terms.f <- function(x){
    split.terms <- stringr::str_split(x[,"keywords"], pattern =";")
    clean.terms <- lapply(split.terms, function(x) gsub(" ", "", x))
    }
    
keywords.decade <- lapply(keywords.data.split, terms.f)
keywords.decade <- lapply(keywords.decade, unlist)

temp <- lapply(keywords.decade, function(x) data.frame(table(x)))
temp <- lapply(temp, function(x) arrange(x, desc(Freq)))
lapply(temp, function(x) head(x,10))    
```


# What are the most frequent topic areas (by author specified keywords)?
  
```{r keywords_overall, comment=NA, warning=FALSE, message=FALSE}
kp.df <- filter(pi.df, attributes == "KP")

subject.terms <- stringr::str_split(kp.df$record, pattern = ";")
subject.terms <- unlist(lapply(subject.terms, function(x) gsub(" ", "", x)))
subject.terms.total <- length(unlist(lapply(subject.terms, 
                        function(x) gsub(" ", "", x))))

subject.terms.unique <- length(unique(subject.terms))

subject.terms.l <- list(subject.terms.total = subject.terms.total,
                      subject.terms.unique = subject.terms.unique)

most.frequent <- as.data.frame(table(subject.terms))

most.frequent <- arrange(most.frequent, desc(Freq))

# Print summary statistics
print(subject.terms.l)

# Print 25 most frequent
head(most.frequent, 25)
```

## Most Frequent Author Keywords

```{r keywords_over_time, warning=FALSE, message=FALSE}
decade <- filter(pi.df, attributes == "YR") %>%
    mutate(year = as.numeric(record)) %>% select(-record, -attributes)

decade$year <- cut(decade$year, breaks = 10, labels = c(1:10))

keywords <- pi.df %>%
        filter(attributes == "KP") %>%
        select(articleID = articleID, keywords = record)

keywords.decade <- keywords %>% 
         left_join(decade)

library(plyr)
keywords.data.split <- dlply(keywords.decade, .(year))
detach(package:plyr)

terms.f <- function(x){
    split.terms <- stringr::str_split(x[,"keywords"], pattern =";")
    clean.terms <- lapply(split.terms, function(x) gsub(" ", "", x))
    }
    
keywords.decade <- lapply(keywords.data.split, terms.f)
keywords.decade <- lapply(keywords.decade, unlist)

temp <- lapply(keywords.decade, function(x) data.frame(table(x)))
temp <- lapply(temp, function(x) arrange(x, desc(Freq)))
lapply(temp, function(x) head(x,10))    
```



# Location of Studies 

```{r location, comment=NA, warning=FALSE, message=FALSE}

LO.df <- filter(pi.df, attributes == "LO")


subject.terms <- stringr::str_split(LO.df$record, pattern = ";")
subject.terms <- unlist(lapply(subject.terms, function(x) gsub(" ", "", x)))
subject.terms.total <- length(unlist(lapply(subject.terms, function(x) gsub(" ", "", x))))
subject.terms.unique <- length(unique(subject.terms))

subject.terms.l <- list(subject.terms.total = subject.terms.total,
                      subject.terms.unique = subject.terms.unique)

most.frequent <- as.data.frame(table(subject.terms))

location <- arrange(most.frequent, desc(Freq))

print(subject.terms.l)

print(location)

img2 <- readPNG("/Users/beperron/Git/SocialWorkResearch/Chloro.png")
grid.raster(img2)
```


## Location of studies over time

```{r location_over_time, warning=FALSE, message=FALSE}

year <- filter(pi.df, attributes == "YR") %>%
    mutate(year = as.numeric(record)) %>% select(-record, -attributes)

location.temp <- pi.df %>%
        filter(attributes == "LO") %>%
        select(articleID = articleID, country = record) %>%
        mutate(country = gsub(" ", "", country))

location.year <- location.temp %>% 
         left_join(year) %>%
         group_by(country, year) %>%
         summarise(n = n()) %>%
         arrange(country, year, n)

top.locations <- location %>% 
                 select(subject.terms) %>%
                 rename(country = subject.terms) %>%
                 slice(1:5)

location.year.top <- location.year %>% filter(country %in% top.locations$country)
ggplot(location.year.top, aes(x = year, y = n, colour = country )) + geom_line()


top.locations.no.us <- location %>% 
                select(subject.terms) %>%
                rename(country = subject.terms) %>%
                slice(2:7)

location.year.top.no.us <- location.year %>% filter(country %in% top.locations.no.us$country)

ggplot(location.year.top.no.us, aes(x = year, y = n, colour = country )) + geom_line()

```

## Countries not represented in social work research 

This section is currently not functional
```{r countries_not_represented}
#Tableau.countries <- read.csv("/Users/beperron/Git/SocialWorkResearch/SupportingDocs/Tableau\ Countries.csv")
```

# Methodology

```{r methodology, comment=NA, warning=FALSE, message=FALSE}

MD.df <- filter(pi.df, attributes == "MD")

methodology <- stringr::str_split(MD.df$record, pattern = ";")
methodology.terms <- unlist(lapply(methodology, function(x) gsub(" ", "", x)))
               
methodology.table <- as.data.frame(table(methodology.terms))
methodology.table <- arrange(methodology.table, desc(Freq))

```

## Methodology over time

```{r}
year <- filter(pi.df, attributes == "YR") %>%
    mutate(year = as.numeric(record)) %>% select(-record, -attributes)


methodology <- pi.df %>%
        filter(attributes == "MD") %>%
        select(articleID = articleID, method = record) %>%
        mutate(method = gsub(" ", "", method))

methodology.year <- methodology %>% 
         left_join(year) %>%
         group_by(method, year) %>%
         summarise(n = n()) %>%
         arrange(method, year, n)

methodology.year.top <- slice(methodology.table, 1:5) %>%
         rename(method = methodology.terms) %>%
         mutate(method = gsub(" ", "", method))

methodology.year.reduced <- methodology.year %>%
        filter(method %in% methodology.year.top$method)

ggplot(methodology.year.reduced, aes(x = year, y = n, colour = method)) + 
        geom_line()
```







## Number of authors
```{r comment=NA, message=FALSE, warning=FALSE}
n.authors.article <- pi.df %>% 
    filter(attributes == "AU") %>%
    select(id = articleID, author= record) %>%
    mutate(id = as.numeric(id))

n_authors <- n.authors.article %>% 
        group_by(id) %>%
        summarise(n = n())

ggplot(n_authors, aes(x = factor(n))) + 
    geom_bar() + 
    stat_bin(binwidth=1) +
    xlab("Number of Listed Authors") + 
    ylab("Number of Articles")
    

summary(n_authors$n)
```

## Number of authors over time

This figure shows the average number of authors, along with the standard deviation as the ribbon around the average.  Note that there is a possible problem in these data, with a single article listing a huge number.  That can be corrected at a later time. 


```{r message=FALSE, comment=NA, warning=FALSE, fig.height=2, fig.height=4}
df.2 <- tbl_df(pi.df)
year <- df.2 %>%
        filter(attributes == "YR") %>%
        select(id = articleID, year = record)

authors <- df.2 %>%
        filter(attributes == "AU") %>%
        select(id = articleID, author = record)

n_authors <- authors %>%
        group_by(id) %>%
        summarise(n=n())

n_authors <- n_authors %>% 
        left_join(year) %>%
        group_by(year) %>%
        summarise(median.n = median(n),
                  average.n = mean(n),
                  min.n = min(n),
                  max.n = max(n),
                  std.dev  = sd(n) )

plot.author.count2 <- ggplot(n_authors, aes(as.numeric(year), y=average.n, group=1)) + 
    geom_line(colour="black") + 
    geom_ribbon(aes(ymin = average.n-std.dev, ymax=average.n+std.dev), alpha=.2)

head(n_authors, 20)
tail(n_authors, 20)
plot.author.count2
```


