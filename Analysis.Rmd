---
title: '100 Years of Social Work Research: A Data Science Perspective'
output: html_document
---

Data collection date:  January 8, 2014

Database: PsychInfo (via EbscoHost Platform) 

Search terms:  SO "social work" or SO "social welfare" or SO "social casework" or "social case work" or SO "social service" or "social services" or SO "human service" or SO "human services" or SO "social development" or SO "social environment" 

Search limiters:  Publication Type: Peer Reviewed Journal; Document Type: Journal Article

Search modes: Boolean/Phrase

Search results were exported from EbscoHost Platformon in a _generic bibliographic format_.  This is an unstructured text file (*.txt) that was processed using in R.  

```{r initialization_dataprocessing, warning=FALSE, message=FALSE, eval=FALSE}
# Clear workspace
rm(list=ls())

# Read BWR functions for Mac OS
source("/Users/beperron/Git/BibWrangleR/functions/piWrangleR.R")
source("/Users/beperron/Git/BibWrangleR/functions/packages.R")
# Set the path where original raw data are stored
setwd("/Users/beperron/Git/SocialWorkResearch/Data")

# Set the working directory to store files created by BWR functions
path <- "/Users/beperron/Git/SocialWorkResearch/Data"

# Wrangle the data with the BWR function suite
#piBWR.f(csv=FALSE, path=path)
#save(pi.df, file = "piArticles.R")
```


```{r initialization_analysis, message=FALSE, warning=FALSE, comment=NA, echo=FALSE}
rm(list=ls())
setwd("/Users/beperron/Git/SocialWorkResearch/Data")
source("/Users/beperron/Git/BibWrangleR/functions/ggsurv.R")
load("piArticles.R")
library(dplyr)
library(ggplot2)
library(gridExtra)
library(survival)
library(grid)
library(png)


# Inspect dimensions of the data file (Rows X Columns)
dim(pi.df)

# Inspect variable names of the data file
names(pi.df)

# How many unique article titles?  Ebsco Results of most current search is $n=XXXX$. Do not proceed with analysis if the output does not match this result.  
length(which(pi.df$attributes == "TI"))
```


Note the exclusion of social work today.

```{r echo=FALSE}
pi.df <- pi.df %>% filter(
        record != "Journal of Applied Social Sciences" &
        record != "Early Child Development and Care" &
        record != "The Clinical Supervisor" &
        record != "Children and Youth Services Review" &
        record != "General Hospital Psychiatry" &
        record != "Canadian Journal on Aging" &
        record != "Canadian Journal of Community Mental Health" &
        record != "Behavior Modification" &
        record != "Employee Assistance Quarterly" &
        record != "Journal of Applied Behavioral Science" & 
        record != "The Scientific Review of Mental Health Practice: Objective Investigations of Controversial and Unorthodox Claims in Clinical Psychology, Psychiatry, and Social Work" &
        record != "Systems Research and Behavioral Science" & 
        record != "Journal of Applied Rehabilitation Counseling" & 
        record != "Journal of Educational & Psychological Consultation" &
        record != "Journal of Community & Applied Social Psychology" &                                          
        record != "Evaluation and Program Planning" &                                                                  
        record != "Journal of Nonverbal Behavior" &
        record != "Brain and Cognition" &
        record != "Early Education and Development" & 
        record != "American Journal of Preventive Medicine" &
        record != "Social Work Today")
```


This section provides further cleaning of retained journals, namely merging two journals with abbreviated titles:

```{r}

pi.df$record <- ifelse(pi.df$record == "Practice", "Practice: Social Work in Action", pi.df$record)
pi.df$articleID <- ifelse(pi.df$articleID == 74, 42, pi.df$articleID)

pi.df$record <- ifelse(pi.df$record == "Eugenics & Social Welfare Bull.", "Eugenics and Social Welfare Bulletin", pi.df$record)
pi.df$articleID <- ifelse(pi.df$articleID == 28, 32, pi.df$articleID)

```


```{r unique_titles, echo=FALSE}
unique.titles <- filter(pi.df, attributes == "SO")

# Number of unique titles
number.journals <- length(unique(unique.titles$record))

# Unique titles
journals.unique <- unique(unique.titles$record)
#write.csv(journals.unique, "journals.csv")

number.journals
journals.unique
```


```{r unique_titles_year, message=FALSE, comment=NA, warning=FALSE, fig.height=2, fig.height=4, echo=FALSE}
journals.year <- tbl_df(pi.df)

year <- journals.year %>%
        filter(attributes == "YR") %>%
        select(id = articleID, year = record)

journals <- journals.year %>%
        filter(attributes == "SO") %>%
        select(id = articleID, journal.title = record)

n.journals.year <- journals %>% 
        left_join(year) %>%
        group_by(year) %>%
        distinct(journal.title) %>%
        summarise(n = n())

journal.count <- ggplot(n.journals.year, aes(as.numeric(year), y=n, group=1)) + 
    geom_line(colour="black") +
    #geom_point(colour="red") + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
    xlab("Publication year") + 
    ylab("Number") + 
    ggtitle("Number of Journals Over Time") + 
    scale_x_continuous(breaks=seq(1914, 2014, 5))
        
journal.count
```


## What journals published the most number of articles

```{r journal_output, echo=FALSE}

n.so.yr <- filter(pi.df, attributes == "SO" | attributes == "YR")

n.so <- filter(pi.df, attributes == "SO") %>% mutate(title = record) %>% 
        select(-attributes, -record)

n.yr <- filter(pi.df, attributes == "YR") %>% mutate(year = record ) %>% 
        select(-attributes, -record)

n.so.yr <- left_join(n.so, n.yr) %>%
    group_by(title) %>%
    summarise(first = min(year), last = max(year), n.to.date = n()) %>%
    arrange(desc(n.to.date))

# 10 highest number of publications
head(n.so.yr, 10)
```

## What is the lifespan of journals?  

```{r journal_lifespan, echo=FALSE}
#10 longest running journals 
longest.running <- n.so.yr %>%
       mutate(last = as.numeric(last), first = as.numeric(first), 
              year.diff = last - first) %>%
       arrange(desc(year.diff)) %>%
       select(title, first, last, year.diff) %>%
       mutate(stop = year.diff, event = ifelse(as.numeric(last) != 2013, 1, 0)) %>%
       select(title, stop, event, as.numeric(first))

survival.journals <- survfit(Surv(longest.running$stop+1, longest.running$event) ~ 1)
median.survival <- data.frame(time = c(24,24), quant = c(.5,0))

head(longest.running)

ggsurv(survival.journals) + 
    geom_line(data = median.survival, aes(time, quant), linetype="longdash") +
    annotate("segment", x = 32, xend = 27, y = .12, yend = .12, size = .25, arrow =arrow()) +
    geom_text(x = 45, y =.12, label = "median survival", size = 4) + 
    geom_text(x = 75, y =.75, label = "+ = Last year of indexing", size = 4) +
    ylim(0,1) +
    xlim(0,100) + 
    xlab("Survival Time (in years)") +
    ylab("Survival Probability") +
    ggtitle("Survival Probability of Social Work Journals")

```

## What is the number of articles published per year

```{r articles_per_year, echo=FALSE}
n.articles.year <- filter(pi.df, attributes == "YR") 
year.split <- split(n.articles.year, n.articles.year$record)
year.count <- unlist(lapply(year.split, nrow))
year.count <- year.count[order(names(year.count))]
years <- names(year.count)

df <- data.frame(years, year.count)
rownames(df) <- NULL

plot.article.count <- ggplot(df, aes(as.factor(years), 
                    y = year.count, group=1)) + 
    geom_line(colour="black") +
    #geom_point(colour="red") + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
    xlab("year") + 
    ylab("count") + 
    ggtitle("Number of Studies by Year") +
    scale_x_discrete(breaks=c(seq(1914, 2015, 10))) +
    scale_y_continuous(breaks = c(seq(0, 2000, 250))) 
   

df$years <- as.numeric(as.character(df$years))

plot.article.cumulative <- ggplot(df, aes(x = years, y = cumsum(year.count))) + 
    geom_line() + 
    theme(axis.text.x = element_text(angle=45, hjust=1)) +
    scale_x_continuous(breaks=pretty(df$years)) +
    xlab("year") +  
    ylab("count") +
    scale_x_continuous(breaks = c(seq(1914,2014,10))) +
    scale_y_continuous(breaks = c(seq(0, 25000, 2500))) + 
    ggtitle("Cumulative Frequency") 
   

grid.arrange(plot.article.count, plot.article.cumulative, ncol=2)

# Print most recent ten years
tail(df, 10)
```





# What are the most frequent topic areas (by author specified keywords)?
  
```{r keywords_overall, comment=NA, warning=FALSE, message=FALSE, echo=FALSE}
kp.df <- filter(pi.df, attributes == "KP")

subject.terms <- stringr::str_split(kp.df$record, pattern = ";")
subject.terms <- tolower(subject.terms)
subject.terms <- unlist(lapply(subject.terms, function(x) gsub(" ", "", x)))
subject.terms.total <- length(unlist(lapply(subject.terms, 
                        function(x) gsub(" ", "", x))))

subject.terms.unique <- length(unique(subject.terms))

subject.terms.l <- list(subject.terms.total = subject.terms.total,
                      subject.terms.unique = subject.terms.unique)

most.frequent <- as.data.frame(table(subject.terms))

most.frequent <- arrange(most.frequent, desc(Freq))

# Print summary statistics
print(subject.terms.l)

# Print 25 most frequent
head(most.frequent, 25)
```

## Most Frequent Author Keywords

For this analysis (to-do), select a few keywords that may tell an interesting story of how they change over time -- something that might be revealing of 'trends.' 

+ social justice
+ evidence-based practice" | "evidence based practice" | "EBP"
+ bullying
+ child welfare

```{r keywords_over_time, warning=FALSE, message=FALSE, echo=FALSE}
kp.yr <- filter(pi.df, attributes == "YR") %>%
    mutate(year = as.numeric(record)) %>% select(-record, -attributes)

kp <- pi.df %>%
        filter(attributes == "KP") %>%
        select(articleID = articleID, keyword = record) %>%
        mutate(keyword = gsub(" ", "", keyword))

kp.year <- kp %>% 
         left_join(kp.yr) %>%
         group_by(keyword, year) %>%
         summarise(n = n()) %>%
         arrange(keyword, year, n)


select.keywords <- c("depression", "hiv")
select.keywords.df <- kp.year %>% filter(tolower(keyword) %in% select.keywords)

library(plyr) # Fix code so ply loads before dplyr
key.plot.df <- ddply(select.keywords.df, .(keyword), transform, cumulative = cumsum(n))
detach(package:plyr)

#Fix graph to sort the keywords / colour
ggplot(key.plot.df, aes(x = year, y = cumulative, colour = keyword, group = keyword)) + 
    geom_line() +
    ggtitle("Cumulative Sum of Articles by Keywords") +
    ylab("Cumulative Sum") + 
    xlab("Year") + 
    theme(legend.title=element_blank()) 
   
```



# Location of Studies 

```{r location, comment=NA, warning=FALSE, message=FALSE, echo=FALSE}
LO.df <- filter(pi.df, attributes == "LO") %>%
         group_by(record) %>%
         summarise(Country = unique(record),
                   N = n()) %>%
        arrange(desc(N)) %>% 
        select(-record)

locations <- as.data.frame(table(LO.df))
locations <- arrange(locations, desc(Freq))
locations.unique <- length(unique(locations))

#write.csv(locations, "location.csv")

#img2 <- readPNG("/Users/beperron/Git/SocialWorkResearch/Chloro.png")
#grid.raster(img2)
```


## Location of studies over time

```{r location_over_time, warning=FALSE, message=FALSE, echo=FALSE}
library(RColorBrewer)
year <- filter(pi.df, attributes == "YR") %>%
    mutate(year = as.numeric(record)) %>% select(-record, -attributes)

location.temp <- pi.df %>%
        filter(attributes == "LO") %>%
        select(articleID = articleID, country = record) %>%
        mutate(country = gsub(" ", "", country))

location.year <- location.temp %>% 
         left_join(year) %>%
         group_by(country, year) %>%
         summarise(n = n()) %>%
         arrange(country, year, n) %>%
         mutate(cumsum_n = cumsum(n), log_n = log(n+1))


top.locations <- LO.df %>% 
                 select(Country) %>%
                 slice(1:5) 

top.locations$Country <- gsub(" ", "", top.locations$Country)


    
location.year.top <- location.year %>% filter(country %in% top.locations$Country)




ggplot(location.year.top, aes(x = year, y = log_n, colour = country )) + 
    geom_line(size = 1.25) +
    ggtitle("Log Number of Articles by Countries With Highest Scholarly Ouput") +
    xlab("Publication Year") + 
    ylab("log N+1") +
    theme(legend.position=c(.210, .7))


top.locations.no.us <- LO.df %>% 
                select(Country) %>%
                slice(2:10)

top.locations.no.us$Country <- gsub(" ", "", top.locations.no.us$Country)

location.year.top.no.us <- location.year %>% filter(country %in% top.locations.no.us$Country) 

ggplot(location.year.top.no.us, aes(x = year, y = cumsum_n, colour = country )) + geom_line(size=1.00) +
    ggtitle("Cumulative Number of Article by Countries with Highest Scholarly Output \n(Excluding the United States)") +
    theme(legend.position=c(.210, .6))
```

## Countries not represented in social work research 

This section is currently not functional
```{r countries_not_represented, echo=FALSE}
#Tableau.countries <- read.csv("/Users/beperron/Git/SocialWorkResearch/SupportingDocs/Tableau\ Countries.csv")
```


## Number of authors
```{r comment=NA, message=FALSE, warning=FALSE, echo=FALSE}
n.authors.article <- pi.df %>% 
    filter(attributes == "AU") %>%
    select(id = articleID, author= record) %>%
    mutate(id = as.numeric(id))

n_authors.1 <- n.authors.article %>% 
        group_by(id) %>%
        summarise(n = n())

n_authors.1t <- n_authors.1 %>% mutate(n = ifelse(n >=6, 6, n)) %>% 
    group_by(n) %>%
    summarise(Articles = n())

ggplot(n_authors.1t, aes(x = n, y = Articles)) +
    geom_bar(stat="identity", colour="black", fill = "white") +
    geom_text(aes(label = Articles), vjust=-.3, size = 4) +
    scale_x_discrete(limits = c(as.character(1:5), "6+")) + 
    ggtitle("Number of Articles by Author Count") + 
    xlab("Author Count") + 
    ylab("Articles")
```

## Number of authors over time

This figure shows the average number of authors, along with the standard deviation as the ribbon around the average.  Note that there is a possible problem in these data, with a single article listing a huge number.  That can be corrected at a later time. 


```{r message=FALSE, comment=NA, warning=FALSE, fig.height=2, fig.height=4, echo=FALSE}
df.2 <- tbl_df(pi.df)
year <- df.2 %>%
        filter(attributes == "YR") %>%
        select(id = articleID, year = record)

authors <- df.2 %>%
        filter(attributes == "AU") %>%
        select(id = articleID, author = record)


n_authors <- authors %>%
        group_by(id) %>%
        summarise(n=n())

n_authors <- n_authors %>% 
        left_join(year) %>%
        group_by(year) %>%
        summarise(median.n = median(n),
                  average.n = mean(n),
                  min.n = min(n),
                  max.n = max(n),
                  std.dev  = sd(n) )

plot.author.count2 <- ggplot(n_authors, aes(as.numeric(year), y=average.n, group=1)) +  
    geom_ribbon(aes(ymin = average.n-std.dev, ymax=average.n+std.dev), colour="lightblue", fill="lightblue", alpha=.40) +
    geom_line(colour="black") + 
    geom_segment(aes(x= 1940, y = 5.5, xend = 1935, yend = 5.5), 
                 arrow=arrow(length=unit(0.25, "cm"))) +
    annotate("text", x = 1951, y = 5.5, label = "1 outlier case of \n24 listed authors", size=3.5) +
    ylab("Average number of authors (black) \nStandard deviation (light blue)") +
    xlab("Publication year") +
    ggtitle("Average Number of Authors per Article Over Time")

plot.author.count2


```



