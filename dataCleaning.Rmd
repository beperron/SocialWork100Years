---
title: "25 years of Social Work Research"
author: "Summary of Data Cleaning Procedures"
output: pdf_document
---

`r knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, comment=NA)`

```{r initialization_dataprocessing}
rm(list=ls())   
# Load required packages
library(ggplot2)
library(dplyr)

# Read data files
load("/Users/beperron/Git/SocialWorkResearch/Data/ebscoFULL.R")
load("/Users/beperron/Git/SocialWorkResearch/Data/proQuest.R")
hodge <- readLines("/Users/beperron/Git/SocialWorkResearch/search_specifications/hodge.txt", n = -1)
#load("/Users/SSW/Documents/GitHub/SocialWork100Years/Data/ebscoFULL.R")
#load("/Users/SSW/Documents/GitHub/SocialWork100Years/Data/proQuest.R")
#hodge <- readLines("/Users/SSW/Documents/GitHub/SocialWork100Years/search_specifications/hodge.txt", n = -1)

# Load special functions
source("/Users/beperron/Git/SocialWorkResearch/functions/appendData.R")
source("/Users/beperron/Git/SocialWorkResearch/functions/shortArticles.R")
source("/Users/beperron/Git/SocialWorkResearch/functions/titleMatching.R")
source("/Users/beperron/Git/SocialWorkResearch/functions/otherDocuments.R")
source("/Users/beperron/Git/SocialWorkResearch/functions/titleMatching.R")
source("/Users/beperron/Git/SocialWorkResearch/functions/fewArticles.R")

pretty <- function(x){
    x <- prettyNum(x,big.mark=",",scientific=F)
    x
    }
```

```{r appendData, comment=NA, echo=FALSE}
appendData.f()

append.articles <- length(which(full.df$attributes == "article"))
append.journals <- filter(full.df, attributes == "journal") %>% 
    summarise(Unique = n_distinct(record))

unique.titles <- filter(full.df, attributes == "journal") %>%
    group_by(record) %>%
    summarise(
        N = n())
```

```{r shortArticles, comment=NA, echo=FALSE, warning=FALSE}
shortArticles.f()
```

```{r titleMatching, echo=FALSE}
titleMatching.f()

articles.titleMatching <- length(which(full.df$attributes == "article"))

journals.titleMatching <- filter(full.df, attributes == "journal") %>%
        summarise(Unique = n_distinct(record))
```  

```{r otherDocuments, echo=FALSE}
otherDocuments.f()
articles.otherDocuments <- length(which(full.df$attributes == "article"))
journals.otherDocuments <- filter(full.df, attributes == "journal") %>% 
    summarise(Unique = n_distinct(record))
```

```{r final, comment=NA, echo=FALSE}
fewArticles.f()
articles.final <- length(which(full.df$attributes == "article"))
journals.final <- filter(full.df, attributes == "journal") %>% 
    summarise(Unique = n_distinct(record))
```

```{r finalList, comment=NA, echo=FALSE}
unique.titles <- filter(full.df, attributes == "journal") %>%
    group_by(record) %>%
    summarise(N = n())

unique.titles <- filter(full.df, attributes == "journal") %>%
    group_by(record) %>%
    mutate(Hodge.list = ifelse(record %in% hodge == TRUE, 1, 0)) %>%
    summarise(N = n(), 
              Hodge.list = max(Hodge.list)) %>%
    mutate(Hodge = ifelse(Hodge.list == 1, "Y", "N"))


n.so.yr <- filter(full.df, attributes == "journal" | attributes == "pubYear")

n.so <- filter(full.df, attributes == "journal") %>% mutate(title = record) %>% 
        select(-attributes, -record)

n.yr <- filter(full.df, attributes == "pubYear") %>% mutate(year = record ) %>% 
        select(-attributes, -record)

n.so.yr <- left_join(n.so, n.yr) %>%
    group_by(title) %>%
    summarise(first = min(year), last = max(year), n = n()) %>%
    arrange(title)

H <- unique.titles$Hodge

final.list <- cbind(n.so.yr, H)
```

```{r plotArticleCount}
n.articles.year <- filter(full.df, attributes == "pubYear") 
year.split <- split(n.articles.year, n.articles.year$record)
year.count <- unlist(lapply(year.split, nrow))
year.count <- year.count[order(names(year.count))]
years <- names(year.count)

articles.year.df <- data.frame(years, year.count)
rownames(articles.year.df) <- NULL

plot.article.count <- ggplot(articles.year.df, aes(as.factor(years), 
                    y = year.count, group=1)) + 
    geom_line(colour="black") +
    #geom_point(colour="red") + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
    xlab("Year") + 
    ylab("Number of articles") + 
    ggtitle("Number of Articles Published Over Time") +
    scale_x_discrete(breaks=c(seq(1988, 2013, 2))) +
    scale_y_continuous(breaks = c(seq(0, 2500, 200))) +
    geom_smooth()
```

```{r plotJournalCount}
n.journals.year <- filter(full.df, attributes == "journal") %>%
    select(articleID, record)

n.year <- filter(full.df, attributes == "pubYear") %>%
    select(articleID, record)

n.journals.year <- left_join(n.journals.year, n.year, by = "articleID", copy=TRUE) %>%
    group_by(record.y) %>%
    summarise(Journal.count = n_distinct(record.x))

plot.journal.count <- ggplot(n.journals.year, aes(as.factor(record.y), 
                    y = Journal.count, group=1)) + 
    geom_line(colour="black") +
    #geom_point(colour="red") + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
    xlab("Year") + 
    ylab("Number of journals") + 
    ggtitle("Number of Social Work Journals Over Time") +
    scale_x_discrete(breaks=c(seq(1988, 2013, 2))) +
    scale_y_continuous(breaks = c(seq(0, 100, 10))) +
    geom_smooth()
```


```{r plotAuthorCount}

year.df <- full.df %>%
        filter(attributes == "pubYear") %>%
        select(id = articleID, pubYear = record)

authors.df <- full.df %>%
        filter(attributes == "author") %>%
        select(id = articleID, author = record)


n_authors <- authors.df %>%
        group_by(id) %>%
        summarise(n=n())

n_authors <- n_authors%>% 
        left_join(year.df) %>%
        group_by(pubYear) %>%
        mutate(n = as.numeric(n)) %>%
        summarise(median.n = median(n),
                  average.n = mean(n),
                  min.n = min(n),
                  max.n = max(n),
                  std.dev  = sd(n) )

plot.author.count <- ggplot(n_authors, aes(as.factor(pubYear), y=median.n, group=1)) +  
    geom_ribbon(aes(ymin = average.n-std.dev, ymax=average.n+std.dev), colour="lightblue", fill="lightblue", alpha=.40) +
    geom_line(colour="black") + 
    ylab("Number of authors") +
    xlab("Publication year") +
    ggtitle("Number of Authors per Article Over Time") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
    scale_x_discrete(breaks=c(seq(1988, 2013, 2))) +
    geom_smooth()
```

# Methods

### Extraction of article records

Our list of social work journals was guided by the work of Hodge and Lacasse (2011).  More specifically, Hodge and Lacasse (2011) identified 84 disciplinary social work journals based on a variety of sources, including _An Author’s Guide to Social Work Journals_ (NASW Press, 1997), Thyer’s (2005) more recent listing of social work periodicals, and Genamics JournalSeek (http://journalseek.net/). Hodge and Lacasse (2011) examined the mission and aims of each journal, and eliminated journals that were specific to another field or had an had an inter-disciplinary focus.  For the current study, our primary search query included all journal titles in this list.

To help ensure comprehensive coverage of all possible core social work journals, we created a supplemental search query that extracted journal titles with any of the following terms:  

+ "social work"
+ "social welfare"
+ "social casework"
+ "social service" 
+ "human  service" 
+ "social development" 
+ "social environment"

Using this search queries, we extract journal article recrods from three major databases on the EbscoHost platform:  PsycINFO, Social Service Abstracts, and Social Work Abstracts.  Because of known gaps in indexing in databases (Holden, Barker, Kuppens, Rosenberg & LeBreton, 2014; Holden, Barker, Covert-Vail, Rosenberg, & Cohen, 2009), we also searched ProQuest, which linked to an additional 46 minor databases, including (but not limited to): ERIC, Sociological Abstracts and Worldwide Political Science Abstracts.  In every search, we used a filter in attempt to extract only article records that were classified as _journal articles_, thereby excluding other forms of scholarly communication that was not relevant to the current study (e.g., book reviews, editorials, obituaries, etc.).  We limited the timeframe to a 25 year period, from 1988 to 2013 (inclusive).  Articles published in years 2014 and 2015 were excluded because of delays in indexing.  Search results were exported in batches of article records based on the restrictions of the platform.  Article records were text files in a _generic bibliographic format_.  The article records contained various meta-data based on the database from which the article record was extracted.   Meta-data include (but are not limited to):  article title, journal title, publication year, author name(s), author affiliation(s), abstract, keywords, methodological classification, funding source, location of study, subject groups, digital object identifier (DOI), number of references, number of pages, etc.  These files were post-processed into a structured database using a set of scripts written in the R statistical programming language.  The initial search resulted in 36,094 article records from 117 different journals.  

The search queries were purposefully specified to be overly inclusive to ensure full coverage of all possible social work journals contained in the major and minor databases.  Additionally, a visual inspection of the article records revealed problems in the original indexing of articles that requires subsequent data cleaning.  Thus, our data cleaning procedures focused separately on journal titles and article records.


### Data cleaning: Journal titles

The first step of data cleaning involved fixing journal title names due to discrepant errors in indexing. For example, _Journal of Gay and Lesbian Social Services_ was indexed as a journal separate from _Journal of Gay & Lesbian Social Services_ (use of "and" vs. "&").  Other examples involved journals indexed with and without subtitles, or journals with and without the word "The" at the beginning of the title.  Additionally, some journals changed titles over their history.  For example, _Journal of Technnology in Human Services_ is formerly known as _Computers in Human Services_.  In these situations, the former titles were merged with the current titles.  

Many journals from allied health disciplines used one of the supplemental search terms in special editions, which were also included in the journal title.  Thus, many non-social work journals were captured in the extraction process.  To resolve this issue, we created a list of all journal titles that were not part of the core list defined by Hodge and Lacasse (2011).  Study authors reviewed these journal titles and discussed whether each candidate title should be retained or excluded.  When disagreements occurred, the study authors reviewed the mission and aims of the journals, names of editorial board members, and focus of the articles.  A consensus was reached on all journal titles to be excluded and retained.   After these procedures, the number of article records and journal titles was reduced to `r pretty(append.articles)` and `r append.journals` (respectively).  

### Data cleaning:  Article records

Our search procedures involved the use of three major databased and 46 minor databases, which resulted in some duplication of article records.  Thus, a matching algorithm was constructed to identify and remove all duplicate article records. As previously noted, the filtering of only journal articles was not successful due to errors in the original indexing.  Thus, other scholarly communications were captured in the extractio process.  These other scholarly communications were readily identified due to specific patterns in the titles, such as the terms "Book Review," "From the Editor," and "Obituary."  Given the number of article records in the database, it was not feasbile to manually extract these recrods.  Instead, we created a separate database with representative examples of article records that we wanted to extract.  We also added representative examples of article records to be retained.  We then wrote a series of _regular expressions_ to extract the problematic article records.  Regular expressions are a sequence of characters that form search patterns, allowing extraction of records that match the specified pattern.  In other words, it is a more sophisticated implementation of the search function common to all major word processors.  We tested our regular expressions on the test database, achieving > 95% accuracy with regard to retaining and extracting article records.  These regular expressions were then applied to the full database.  We then excluded article records if they were missing essential meta-data, including author name(s), journal title, article title, and publication field.  As an additional requirement, we required all articles to be $\geq 3$ pages in length.   Finally, we eliminated all social work journals with total article counts of < 10 for the enitre 25 year window (_Issues in Social Work Education_, _Maatskaplike Werk/Social Work_, _Pediatric Social Work_, and _Critical Social Work_).  These cleaning procedures resulted in a final database of `r pretty(articles.final)` articles and `r journals.final` journals.  

### Data quality checks

We performed a variety of checks on the final database.  Because the size of the database, it was not feasible to manually inspect all records.  Thus, we randomly sampled article records from the database and cross-checked the data we procured with the information listed with the journal's homepage.  We also inspected a scatter plot of the number of article records for each journal by the number of years the journal appeared within the 25 window timeframe.  Journals that exhibited significant deviation from the regression line were inspected to ensure that our cleaning procedures did not systematically exclude article records or retain other scholarly communications.  All observed discrepancies were verified as differences in journals actual publication output.  Finally, we also made checks of number of journal article records for various journals indexed in the _Web of Science_.  Although the counts were close -- i.e., within 10% -- similar indexing problems observed from our record extraction were also observed in the _Web of Science_ database, such as misclassification of book reviews as journal articles.  Thus, we are unable to quantify the actual amount of error in our database is due to problems in indexing.  At the same time, we are relying on the same source of data that social work researchers use to inform their work.  Too much cleaning and post-processing of the search results can give rise to validity issues because social work researchers are using an information source that contain the errors we have attempted to eliminate.  The issue of reliability and validity are given further attention in the discussion section of this study.  

# Results

\newpage

```{r finalArticleListecho=FALSE, comment=NA}
print.data.frame(final.list, row.names=FALSE)
```

\newpage

```{r}
plot.author.count
```

\newpage

```{r}
plot.article.count
```

\newpage

```{r}
plot.journal.count
```



```{r}
LO.df <- filter(full.df, attributes == "location") %>%
         group_by(record) %>%
         summarise(Country = unique(record),
                   N = n()) %>%
        arrange(desc(N)) %>% 
        select(-record)

```







\newpage







# Appendix A
```{r intersection}
unique.swHistory <- filter(full.df, attributes == "journal") %>%
                distinct(record)

hodge.swHistory.intersect <- intersect(hodge, unique.swHistory$record)

hodge.swHistory.diff <- setdiff(hodge, unique.swHistory$record)
swHistory.hodge.diff <- setdiff(unique.swHistory$record, hodge)

#hodge.swHistory.union <- union(hodge, unique.swHistory$record)
```


Articles on Hodge and Lacasse (2011) but not in the current study.  

```{r}
print(sort(hodge.swHistory.diff))
```





```{r message=FALSE, warning=FALSE, eval=FALSE}
cor.data <- select(final.list, first, last, n) %>%
            mutate(no.years = as.numeric(last) - as.numeric(first)) 

ggplot(cor.data, aes(x = no.years, y = n)) + 
            geom_point(shape = 1) + 
            geom_smooth() + 
            xlab("Years") + 
            ylab("Number of articles")
```




```{r eval=FALSE}
journalArticleFinder.f <- function(journalTitle, keyword = FALSE, 
                           authorAff = FALSE, abstract = FALSE){
    article.search <- which(full.df$record == journalTitle)
    article.search <- full.df[article.search,]
    article.search.ID <- select(article.search, articleID)
    target.ID <- full.df$articleID %in% article.search.ID$articleID
    journal.article.df <- full.df[target.ID, ]
    journal.article.df <- filter(journal.article.df, attributes == "article")
    journal.article.df <- arrange(journal.article.df, record)
    if(keyword == FALSE){journal.article.df <- filter(journal.article.df, attributes != "keyWord")}
    if(authorAff == FALSE){journal.article.df <- filter(journal.article.df, attributes != "authorAff")}
    if(abstract == FALSE){journal.article.df <- filter(journal.article.df, attributes != "abstract")}
    x.shortened <- gsub(" ", "", journalTitle)
    write.csv(journal.article.df, file = paste0(x.shortened, ".csv"), row.names=F)
    }

journalArticleFinder.f("Journal of Gerontological Social Work")
#journalArticleFinder.f("Social Work")

articles <- filter(full.df, attributes == "article") %>% arrange(record)
write.csv(articles, file = "articles.csv")

```

